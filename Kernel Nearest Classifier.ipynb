{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the second week's assignment which requires me to complete kernel nearest classifier manually by myself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------- #\n",
    "#                         Kernel Nearest Classifier                         #\n",
    "# ------------------------------------------------------------------------- #\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2018/1/15 19:51\n",
    "# @Author  : Jiahao Yang\n",
    "# @Email   : yangjh39@uw.edu\n",
    "\n",
    "# Packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Kernel functions (Reguler version)\n",
    "def gaussianRBF(x, y, sigma2):\n",
    "\n",
    "    # x and y are vectors with length n\n",
    "    # sigma2 is the hyper-parameter for the kernel\n",
    "\n",
    "    return np.exp(-(x-y).pow(2).sum() / sigma2)\n",
    "\n",
    "def polynomialVovk(x, y, p):\n",
    "\n",
    "    # x and y are vectors with length n\n",
    "    # p is the hyper-parameter for the kernel\n",
    "\n",
    "    return sum((1 - ((x*y).sum())**p) / (1 - (x*y).sum()))\n",
    "\n",
    "# Kernel functions (Matrix version)\n",
    "def gaussianRBFm(x, y, sigma2):\n",
    "\n",
    "    # x is a n*m dataframs of n samples with m features and y is a 1*m sample vector\n",
    "    # sigma2 is hyper-parameter\n",
    "    # return a n*1 kernel vector\n",
    "\n",
    "    return sum(np.exp(-(x-y).pow(2).sum(1) / sigma2))\n",
    "\n",
    "def polynomialVovkm(x, y, p):\n",
    "\n",
    "    return sum((1 - (np.dot(x, y))**p) / (1 - np.dot(x, y)))\n",
    "\n",
    "# Data preprocessing\n",
    "def preprocessing(dat):\n",
    "    dat.iloc[:, 0:-1] = (dat.iloc[:, 0:-1] - dat.iloc[:, 0:-1].mean(0)) / (np.std(dat.iloc[:, 0:-1]))\n",
    "    dat.iloc[:, -1] = dat.iloc[:, -1].where(dat.iloc[:, -1] == 1, -1)\n",
    "\n",
    "def modeltraining(traindata, kernelfunc=gaussianRBFm, hyperpara=1):\n",
    "\n",
    "    if traindata is None:\n",
    "        return 0\n",
    "\n",
    "    class1data = traindata.iloc[np.where(traindata.iloc[:, -1] == 1)[0], 0:-1]\n",
    "    class2data = traindata.iloc[np.where(traindata.iloc[:, -1] == -1)[0], 0:-1]\n",
    "\n",
    "    n = len(np.where(traindata.iloc[:, -1] == 1)[0])\n",
    "    m = len(np.where(traindata.iloc[:, -1] == -1)[0])\n",
    "\n",
    "    train1andtrain1 = 0\n",
    "\n",
    "    for j3 in np.arange(n):\n",
    "        onetrain1data = class1data.iloc[j3, :]\n",
    "\n",
    "        train1andtrain1 += kernelfunc(class1data, onetrain1data, hyperpara)\n",
    "\n",
    "    train1andtrain1 *= 1 / (n ** 2)\n",
    "\n",
    "    train2andtrain2 = 0\n",
    "\n",
    "    for j4 in np.arange(m):\n",
    "        onetrain2data = class2data.iloc[j4, :]\n",
    "\n",
    "        train2andtrain2 += kernelfunc(class2data, onetrain2data, hyperpara)\n",
    "\n",
    "    train2andtrain2 *= 1 / (m ** 2)\n",
    "\n",
    "    return train1andtrain1 - train2andtrain2\n",
    "\n",
    "# Nearest-mean classifier\n",
    "def nearestMeanClassifier(traindata, testdata, trainresult, kernelfunc=gaussianRBFm, hyperpara=1):\n",
    "\n",
    "    # The default kernel function is Gaussian kernel with hyper-parameter 1\n",
    "\n",
    "    predictlabel = []\n",
    "\n",
    "    if testdata is None:\n",
    "        return predictlabel\n",
    "\n",
    "    class1data = traindata.iloc[np.where(traindata.iloc[:, -1] == 1)[0], 0:-1]\n",
    "    class2data = traindata.iloc[np.where(traindata.iloc[:, -1] == -1)[0], 0:-1]\n",
    "\n",
    "    n = len(np.where(traindata.iloc[:, -1] == 1)[0])\n",
    "    m = len(np.where(traindata.iloc[:, -1] == -1)[0])\n",
    "    p = len(testdata.iloc[:, 0])\n",
    "\n",
    "    for i in np.arange(p):\n",
    "        onetestdata = testdata.iloc[i, 0:-1]\n",
    "\n",
    "        testandtrain1 = kernelfunc(class1data, onetestdata, hyperpara)\n",
    "\n",
    "        testandtrain1 *= 2 / n\n",
    "\n",
    "        testandtrain2 = kernelfunc(class2data, onetestdata, hyperpara)\n",
    "\n",
    "        testandtrain2 *= 2 / m\n",
    "\n",
    "        predictlabel.append(1 if (testandtrain1 - testandtrain2 + trainresult) > 0 else -1)\n",
    "\n",
    "    return np.array(predictlabel)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Load data and split data into train set and test set\n",
    "    data = pd.read_table(\"spamdata.txt\", sep=' ', header=None)\n",
    "    indicator = pd.read_table(\"spamtraintest.txt\", sep=' ', header=None)\n",
    "\n",
    "    train = data.loc[np.where(indicator == 0)[0].tolist(), :]\n",
    "    test = data.loc[np.where(indicator == 1)[0].tolist(), :]\n",
    "\n",
    "    preprocessing(train)\n",
    "    preprocessing(test)\n",
    "\n",
    "    hyperparameterg = np.arange(1, 140, 7).tolist()\n",
    "    hyperparameterp = np.arange(1, 21, 1).tolist()\n",
    "\n",
    "    errorgaussian, errorpoly = [], []\n",
    "\n",
    "    for i in np.arange(len(hyperparameterg)):\n",
    "\n",
    "        trainresultgaussian = modeltraining(train, gaussianRBFm, hyperparameterg[i])\n",
    "        trainresultpoly = modeltraining(train, polynomialVovkm, hyperparameterp[i])\n",
    "\n",
    "        predictlabelgaussian = nearestMeanClassifier(train, test, trainresultgaussian, gaussianRBFm, hyperparameterg[i])\n",
    "        predictlabelpoly = nearestMeanClassifier(train, test, trainresultpoly, polynomialVovkm, hyperparameterp[i])\n",
    "\n",
    "        errorgaussian.append(sum(predictlabelgaussian != test.iloc[:, -1]) / len(test.iloc[:, -1]))\n",
    "        errorpoly.append(sum(predictlabelpoly != test.iloc[:, -1]) / len(test.iloc[:, -1]))\n",
    "\n",
    "        print(\"Gaussian Error is : \" + str(errorgaussian[-1]))\n",
    "        print(\"Poly Error is : \" + str(errorpoly[-1]))\n",
    "        print(str(len(hyperparameterg) - i - 1) + \" iteration left\")\n",
    "\n",
    "    plt.figure(1)\n",
    "    plt.plot(hyperparameterg, errorgaussian, 'ro-')\n",
    "    plt.xlabel('hyper-parameter')\n",
    "    plt.ylabel('misclassification error')\n",
    "    plt.title('Misclassfication error using Gaussian kernel')\n",
    "\n",
    "    plt.plot(hyperparameterp, errorpoly, 'ro-')\n",
    "    plt.xlabel('hyper-parameter')\n",
    "    plt.ylabel('misclassification error')\n",
    "    plt.title(\"Misclassfication error using Vivk's polynomial kernel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](exercise3.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
